= Титульник =

= Задачи =

1. Изучить принцип работы генеративных конкурирующих сетей (GANs)
2. Создать простейшую сеть на основе MNIST

= Введение =

С развитием компьютерных технологий всё большую и большую популярность захватывает
машинное обучение. Одним из главных его приложения является решение задачи 
классификации: на вход алгоритму поступают некоторые данные, а на выходе алгоритм
определяет принадлежность этих данных к какой-либо группе. Примерами таких 
алгоритмов могут быть кластерный анализ, метод опорных векторов или
логистическая регрессия.

Однако, при усложнении структуры входных данных, использование перечисленных
методов затрудняется. К примеру, при классификации изображений распределение
входных данных для изображений одного и того же класса может сильно различаться.
В таком случае требуется более чувствительный метод.

Эту задачу хорошо решает глубокое обучение. В нём используются нейронные сети,
за основу которых взяты нейронные связи в человеческом мозгу. Глубокое обучение
так называется, поскольку там принимают участие множество скрытых слоёв. Для 
хорошего качества выходных данных необходимо большое количество входных данных,
однако натренированная модель способна классифицировать изображения, которые, 
как может показаться, может классифицировать только человек, например, отличать
фотографии кошек от фотографий собак.

Но что, если перевернуть этот процесс, и в качестве входных данных давать модели
класс данных, а на выходе получать эти данные? Такая модель была предложена
Яном Гудфелоу (????) в 2014 году. Она изобрёл генеративные конкурирующие сети
(Generative Adversarial Networks, GANs). Принцип их работы и будет рассматриваться
далее.

= Основная часть =

== Принцип работы ==

В основе работы генеративных конкурирующих сетей лежит две нейронные сети:
генератор и дискриминатор. Данные сети называются "конкурирующими", поскольку генератор 
и дискриминатор пытаются превзойти друг друга. Генератору на вход поступает случайный
вектор, из которого он пытается создать новые данные, неотличимые от реальных.
Он стремится "переиграть" дискриминатора, то есть сделать данные неотличимыми.
Дискриминатор принимает данные, сгенерированные генератором, и реальные данные; его цель -
отличить их. Другими словами, дискриминатор стремится к тому, чтобы минимизировать свою
функцию потерь, тогда как генератор стремится её максимизировать.

Такая "гонка" в теории игр называется антагонистической игрой, или игрой с нулевой суммой.
Отличительной чертой таких игр является то обстоятельство, что, когда один из игроков
увеличивает свой выигрыш, его оппонент проигрывает в той же степени. Другими словами,
выигрыш одного игрока равен проигрышу другого. 

Для все игр такого типа существует точка, в которой соблюдается равновесие Нэша - так 
называется набор стратегий в игре, при котором ни один из игроков не может увеличить свой 
выигрыш, если другие игроки не меняют своей стратегии.

У генеративных конкурирующих сетей достижение этой точки характеризуется следующими 
условиями:
    * Генератор создаёт искусственные данные, неотличимые от реальных
    * Дискриминатор может лишь случайно отгадать, реальные ли на входе данные или
    искусственные, то есть вероятность правильно отличить искусственные данные от 
    настоящих равна вероятности ошибиться

== Математическое обоснование ==

Генератор (G) получает на вход случайный вектор *z* и производит искусственный образец
данных x*

    G(z) = x* (1)

Дискриминатор (D) получает на вход либо образец данных x*, произведённый генератором, либо
образец реальных данных x. На выходе у дискриминатора значение между 0 и 1, показывающий
вероятность того, что данный образец был реальным.

== Пример построения ==

= Заключение =

= Литература =

= Приложение =
