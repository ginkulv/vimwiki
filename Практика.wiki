= Титульник =

= Задачи =

1. Изучить принцип работы генеративных конкурирующих сетей (GANs)
2. Создать простейшую сеть на основе MNIST

= Введение =

С развитием компьютерных технологий всё большую и большую популярность приобретает
машинное обучение. Одним из главных его приложения является решение задачи 
классификации: на вход алгоритму поступают некоторые данные, а на выходе алгоритм
определяет принадлежность этих данных к какой-либо группе. Примерами таких 
алгоритмов могут быть кластерный анализ, метод опорных векторов или
логистическая регрессия.

Однако, при усложнении структуры входных данных, использование перечисленных
методов затрудняется. К примеру, при классификации изображений распределение
входных данных для изображений одного и того же класса может сильно различаться.
В таком случае требуется более чувствительный метод.

Эту задачу хорошо решает глубокое обучение. В нём используются нейронные сети,
за основу которых взяты нейронные связи в человеческом мозгу. Глубокое обучение
так называется, поскольку там принимают участие множество скрытых слоёв. Для 
хорошего качества выходных данных необходимо большое количество входных данных,
однако натренированная модель способна классифицировать изображения, которые, 
как может показаться, может классифицировать только человек, например, отличать
фотографии кошек от фотографий собак.

Но что, если перевернуть этот процесс, и в качестве входных данных давать модели
класс данных, а на выходе получать эти данные? Такая модель была предложена
Яном Гудфеллоу (????) в 2014 году. Она изобрёл генеративные конкурирующие сети
(Generative Adversarial Networks, GANs). Принцип их работы и будет рассматриваться
далее.

= Основная часть =

== Принцип работы ==

В основе работы генеративных конкурирующих сетей лежит две нейронные сети:
генератор и дискриминатор. Данные сети называются "конкурирующими", поскольку генератор 
и дискриминатор пытаются превзойти друг друга. Генератору на вход поступает случайный
вектор, из которого он пытается создать новые данные, неотличимые от реальных.
Он стремится "переиграть" дискриминатора, то есть сделать данные неотличимыми.
Дискриминатор принимает данные, сгенерированные генератором, и реальные данные; его цель -
отличить их. Другими словами, дискриминатор стремится к тому, чтобы минимизировать свою
функцию потерь, тогда как генератор стремится её максимизировать.

Такая "гонка" в теории игр называется антагонистической игрой, или игрой с нулевой суммой.
Отличительной чертой таких игр является то обстоятельство, что, когда один из игроков
увеличивает свой выигрыш, его оппонент проигрывает в той же степени. Другими словами,
выигрыш одного игрока равен проигрышу другого. 

Для все игр такого типа существует точка, в которой соблюдается равновесие Нэша - так 
называется набор стратегий в игре, при котором ни один из игроков не может увеличить свой 
выигрыш, если другие игроки не меняют своей стратегии.

У генеративных конкурирующих сетей достижение этой точки характеризуется следующими 
условиями:
    * Генератор создаёт искусственные данные, неотличимые от реальных
    * Дискриминатор может лишь случайно отгадать, реальные ли на входе данные или
    искусственные, то есть вероятность правильно отличить искусственные данные от 
    настоящих равна вероятности ошибиться

== Пример построения ==

== Свёрточные нейронные сети ==

Свёрточные нейронные сети (Convolutional Neural Networks, CNN) являются модификацией обычных
полносвязных нейронных сетей. В отличие от последних, CNN получает на вход тензор элементов,
а не вектор. Этот тензор затем проходит операцию свёртки. Данная операция заключается в следующем.

Каждый фрагмент изображения умножается на так называемое ядро свёртки. Оно представляет из себя
обычную матрицу, размер которой составляет, как правило, 2х2, 3х3, 4х4 или 5х5. Эта матрица "двигается"
по изображению на небольшое количество пикселей, называемой страйдом и выбираемое исследователем, и из
полученных значений составляется карта признаков. Значения ядра изначально случайные и корректируются в
результате обучения методом обратного распространения ошибки.

Затем полученные значения проходят через функцию активации. Её главная цель избавиться от линейности
значений. На практике чаще всего используются такие функции активации, как гиперболический тангенс,
сигмоида и линейный выпрямитель (ReLU).

Как правило, после этого значения проходят слой пулинга, или субдискретизации. Его целью является 
уплотнение данных. На этом

== Пример построения улучшенной нейронной сети ==

= Заключение =

В современном мире большое значение имеет машинное обучение и особенно одна из его разновидностей - 
глубокое обучение. Оно представляет из себя сложную структуру нейронных сетей, имитирующих структуру
мозга. Как правило, глубокое обучение используется для таких проблем, как классификация и регрессия.
Однако была разработана структура, позволяющий сетям генерировать новые данные, неотличимые от настоящих.
Она называется генеративно-состязательной сетью.

В основе генеративно-состязательной сети лежит две подсети - генератор и дискриминатор. Первая сеть
должна генерировать новые данные, тогда как вторая должна отличать их от настоящих. Сеть называется
состязательной потому что генератор и дискриминатор пытаются превзойти друг друга, в результате чего
качество обеих сетей улучшается. Для того, чтобы сгенерированные данные были действительно похожи
на реальные, генератор и дискриминатор должны войти в равновесие Нэша. На практике это означает, что
дискриминатор должен отличать реальные данные от созданных правильно с вероятностью 50%.

Для улучшения модели вместо обычных полносвязных нейронных сетей следует использовать свёрточные нейронные
сети. В их основе лежит операция свёртки: прохождения каждого фрагмента изображения через фильтры.
Эти фильтры позволяют не анализировать изображения пиксель за пикселем, а ориентироваться на более общие
черты, за счёт чего улучшается качество моделирования.

На основе датасета MNIST, содержащего в себе тысячи изображений рукописных цифр, были построены обе 
перечисленные генеративно-состязательные нейронные сети, и, как и ожидалось, вторая показала
лучшие результаты. По изображениям видно, что многие сгенерированные цифры неотличимы от настоящих.
Таким образом, цель была выполнена.

= Литература =

= Приложение =
